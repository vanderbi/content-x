# EDI Services

[TOC]

## Information rich metadata

We emphasize [the value of information-rich metadata](the-value-of-metadata) for human and machine understanding. Our [metadata editing tools](creating-metadata-for-publication.md) minimize the required effort while maximizing descriptive content by using algorithms to extract as much information from data as possible automatically. This allows you to focus on communicating the other important aspects of data that cannot be inferred. Our [quality checker](evaluating-a-data-package.md) helps ensure that metadata accurately describes the data.

## Publication quality data for reuse

Our open-access [data repository](https://portal.edirepository.org/nis/home.jsp) provides valuable publication-quality data for future scientific inquiries. We hold a thematically diverse collection of data with temporal extents ranging from days to decades, and a global spatial extent though mostly within the United States. Published data can be [revised and updated](updating-a-data-package.md) while previous versions are still available.

## Tools to support research

We support research with tools to revise a dataset, create a [personalized data catalog](create-a-data-catalog.md), [report to funders](reporting-to-funders.md), [find data](finding-data.md), [explore data](data-exploration.md), [access data](accessing-data.md), or [inject automation](event-notifications.md) into scientific workflows. If you have other needs, tell us, and we will work to incorporate it into our offerings.

## Secure and persistent archive

We assign [Digital Object Identifiers (DOIs)](the-data-package.md#digital-object-identifier-doi) and guarantee immutability for all data for long-term access, transparency, and reuse. The EDI data repository satisfies [DataCite](https://datacite.org/) standards for accurate and consistent identification of digital resources for citation and retrieval purposes and are actively working towards [Core Trust Seal](https://www.coretrustseal.org/) requirements of trustworthy repositories. We participate in the development of data standards (e.g. [FAIR](https://www.go-fair.org/fair-principles/), [TRUST](https://www.nature.com/articles/s41597-020-0486-7), [CARE](https://www.gida-global.org/care)) and adopt their recommendations.

## Timely one-on-one support

Science doesn't operate on banking hours and neither do we. Our team can be reached via [email, Slack, or Zoom](../support/contact-us.md) to address any questions or issues. We offer support and advise on a range of topics from data curation to software design. If we don't have an answer, we can refer you to someone who does.


## Streamlined citation & attribution

All data publications are first class research objects which when cited will be fully attributed to personal [research profiles](orcid-id.md). We work with [ORCID](https://orcid.org/), [ROR](https://ror.org/), [DataCite](https://datacite.org/), and [Crossref](https://www.crossref.org/) to ensure data packages are linked to journal manuscripts where possible and apply [schema.org](https://schema.org/) recommendations to our metadata for automatic update of [Google Scholar](https://scholar.google.com/) and [ORCID](https://orcid.org/) profiles.


## Enhanced discovery

Data in the EDI Repository are findable in the [EDI Data Portal](https://portal.edirepository.org/nis/home.jsp), [DataONE](https://www.dataone.org/), and [Google Dataset Search](https://datasetsearch.research.google.com/). We index metadata features commonly found in user searches for our advanced search interface. As a DataONE member our data are discoverable alongside other repositories in the DataONE Network. And finally, we mark up data package landing pages with schema.org metadata enabling an additional path of discovery by users of the Google Dataset Search.

## Data exploration & analysis

Three data exploration tools provide a quick interactive view into a dataset and thereby deepening understanding of a data package beyond the metadata alone. First, our data exploration tool [DeX](data-exploration.md#data-explorer-dex) is an interface for exploring and subsetting tabular data directly from our data portal. Second, the [datapie R package](data-exploration.md#datapie) provides a similar interface but broadens access to any data published in the DataONE network as well as to data stored on a local computer. Finally, [Data Import Scripts](data-exploration.md#data-import-scripts) are automatically generated for each data package in common languages (MatLab, Python, R, SAS, SPSS, tidyr), providing immediate access to manipulation and analysis.

## Analysis ready data

Original data varies greatly in terms of format and structure, thereby making data reformatting a large component of the synthesis workflow. Our [thematic standardization](thematic-standardization.md) process accelerates integration and synthesis of data within our repository and across collaborating repositories. Two projects, [ecocomDP](thematic-standardization.md#ecocomdp) and [hymetDP](thematic-standardization.md#hymetdp), are now underway and involve collaborations with [LTER](https://lternet.edu/) sites, [NEON](https://www.neonscience.org/), [CUAHSI](https://www.cuahsi.org/), and [GBIF](https://www.gbif.org/).

## Workflow automation

Automating workflows have a larger impact with less effort. Our repository [REST API](rest-api.md) provides programmatic access to data and services for automation of common data curation tasks, reporting to stakeholders, and enables automation of fully open and reproducible science analysis workflows.

## Training & skill building

Our [information management resources](resources-for-information-managers.md) are based on 40+ years of information management expertise, including from the U.S. LTER Network, and contributes to improving data management across the environmental science community. We have begun migrating our training and skill-building to an entirely online and self-learning format to broaden community access while retaining the one-on-one support that makes a lasting impact.

## Personalized data catalogs

Personalized [data catalogs](create-a-data-catalog.md) are simple to create and maintain. This approach leverages the archived data and metadata in our repository to create a searchable index within a personal or project's website, thus reducing overhead while facilitating customized branding and an additional avenue of discovery.


## Linked data & AI applications (Coming Soon)

Semantic annotation enables linked data for better human understanding, machine actionability, and the future of AI-driven scientific applications. Data packages are now being annotated with semantic markup by our data curators and planning for integration of search and use technologies with our repository is under development.


## Computational environments (Coming Soon)

Connecting EDI data to computational environments will decrease compute times and enable effective collaboration within and across research groups. We are working with [CyVerse](https://cyverse.org/) to bring their services to EDI users and are in the process of designing a plan to integrate [Jupyter](https://jupyter.org/) Notebooks and [Binder](https://mybinder.org/) with hosted data.
